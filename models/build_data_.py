import torch
import torch.utils.data as data_utils
import numpy as np


def data_generator_(dir, entpair2id, path2id, ent2id):
    """
    data generator for models use both entity embeddings and entity_pair embeddings.
    dobj^-___join___nsubj m.0_00#m.01gf5z m.0ftxc#m.02mjmr
    path                   pos_entspair    neg_entspair    pos_ent0  pos_ent1  neg_ent2 neg_ent3
    """
    with open(dir+"path_pos_neg.txt") as f:

        for line in f.readlines():
            path, pos, neg = line.split()
            ent0, ent1 = pos.split("#")
            ent2, ent3 = neg.split("#")
            yield path2id[path], entpair2id[pos], entpair2id[neg], ent2id[ent0], ent2id[ent1], ent2id[ent2], ent2id[ent3]



def random_train_dev_split_(data, dev_ratio, batch_size, gpu=True):
    """
    put into a data list generated by data_generator
    :param data: dobj^-___join___nsubj m.0_00#m.01gf5z m.0ftxc#m.02mjmr
    :param dev_ratio: dev_dataset size
    :param batch_size: batch size
    :return: data_loader wrapped in torch DataLoader
    """
    num = len(data)
    indices=list(range(num))
    split = int(np.floor(num*dev_ratio))

    np.random.seed(123)
    np.random.shuffle(indices)
    train_idx, dev_idx = indices[split:], indices[:split]

    print("train_data samples:",len(train_idx))
    print("dev_data samples:", len(dev_idx))

    train_data=data[train_idx]
    dev_data = data[dev_idx]

    if gpu :
        t_data_tensor = torch.LongTensor(train_data[:,0:7].tolist()).cuda()
        train = data_utils.TensorDataset(t_data_tensor)

        d_data_tensor = torch.LongTensor(dev_data[:,0:7].tolist()).cuda()
        dev = data_utils.TensorDataset(d_data_tensor)


        train_loader = torch.utils.data.DataLoader(
            train, batch_size=batch_size, shuffle=True )

        dev_loader = torch.utils.data.DataLoader(
            dev, batch_size=batch_size, shuffle=True)

        return train_loader, dev_loader

    else:

        t_data_tensor = torch.LongTensor(train_data[:, 0:7].tolist())
        train = data_utils.TensorDataset(t_data_tensor)

        d_data_tensor = torch.LongTensor(dev_data[:, 0:7].tolist())
        dev = data_utils.TensorDataset(d_data_tensor)

        train_loader = torch.utils.data.DataLoader(
            train, batch_size=batch_size, shuffle=True)

        dev_loader = torch.utils.data.DataLoader(
            dev, batch_size=batch_size, shuffle=True)

        return train_loader, dev_loader
